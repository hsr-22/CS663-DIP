{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_edges(image):\n",
    "    \"\"\"\n",
    "    Detect edges using the Marr-Hildreth (Laplacian of Gaussian) operator.\n",
    "    :param image: Grayscale image as a NumPy array.\n",
    "    :return: Binary edge map as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Step 1: Apply Gaussian blur\n",
    "    smoothed_image = cv2.GaussianBlur(image, (5, 5), 2)\n",
    "\n",
    "    # Step 2: Compute Laplacian of the image\n",
    "    laplacian = cv2.Laplacian(smoothed_image, cv2.CV_64F)\n",
    "\n",
    "    # Step 3: Detect zero-crossings (binary edge map)\n",
    "    edge_image = np.zeros_like(laplacian)\n",
    "    edge_image[np.abs(laplacian) > 0.05] = 255  # Threshold for zero-crossings\n",
    "\n",
    "    return edge_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def encode_contour_location(edge_image, filename):\n",
    "    # Save edge image as a bi-level image\n",
    "    edge_image = (edge_image * 255).astype(np.uint8)\n",
    "    Image.fromarray(edge_image).save(filename, format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "def encode_edges(edge_image):\n",
    "    \"\"\"\n",
    "    Compress the binary edge image using zlib to simulate JBIG encoding.\n",
    "    :param edge_image: Binary edge map as a NumPy array.\n",
    "    :return: Compressed binary data.\n",
    "    \"\"\"\n",
    "    # Flatten and compress the edge image\n",
    "    compressed_data = zlib.compress(edge_image.tobytes())\n",
    "    return compressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_and_subsample(image, edge_image, q=4, d=5):\n",
    "    \"\"\"\n",
    "    Quantize and subsample pixel values adjacent to edges.\n",
    "    :param image: Grayscale image as a NumPy array.\n",
    "    :param edge_image: Binary edge map as a NumPy array.\n",
    "    :param q: Quantization level (bits).\n",
    "    :param d: Subsampling step.\n",
    "    :return: Quantized values and positions.\n",
    "    \"\"\"\n",
    "    adj_pixels = []\n",
    "    indices = np.argwhere(edge_image > 0)\n",
    "\n",
    "    for i, j in indices:\n",
    "        neighbors = image[max(0, i-1):i+2, max(0, j-1):j+2].flatten()\n",
    "        adj_pixels.extend(neighbors)\n",
    "\n",
    "    # Quantize adjacent pixel values\n",
    "    quantized_values = (np.array(adj_pixels) // (256 // (2**q))) * (256 // (2**q))\n",
    "\n",
    "    # Subsample pixel values\n",
    "    subsampled_values = quantized_values[::d]\n",
    "    return subsampled_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def store_encoded_data(filename, edge_file, quantized_values, q, d):\n",
    "    data = {\n",
    "        \"edge_file\": edge_file,\n",
    "        \"quantized_values\": quantized_values.tolist(),\n",
    "        \"quantization_level\": q,\n",
    "        \"sampling_distance\": d,\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import Counter\n",
    "\n",
    "def huffman_encode(data):\n",
    "    \"\"\"\n",
    "    Perform Huffman encoding on the given data.\n",
    "    :param data: Iterable data to encode.\n",
    "    :return: Huffman tree and encoded binary string.\n",
    "    \"\"\"\n",
    "    freq = Counter(data)\n",
    "    heap = [[weight, [symbol, \"\"]] for symbol, weight in freq.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        lo = heapq.heappop(heap)\n",
    "        hi = heapq.heappop(heap)\n",
    "        for pair in lo[1:]:\n",
    "            pair[1] = '0' + pair[1]\n",
    "        for pair in hi[1:]:\n",
    "            pair[1] = '1' + pair[1]\n",
    "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
    "\n",
    "    huffman_dict = dict(heapq.heappop(heap)[1:])\n",
    "    encoded_data = \"\".join(huffman_dict[symbol] for symbol in data)\n",
    "    return huffman_dict, encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import laplace\n",
    "\n",
    "def reconstruct_image(edge_image, quantized_values, image_shape):\n",
    "    \"\"\"\n",
    "    Reconstruct the image by solving Laplace's equation for missing regions.\n",
    "    :param edge_image: Binary edge map as a NumPy array.\n",
    "    :param quantized_values: Quantized values adjacent to edges.\n",
    "    :param image_shape: Shape of the original image.\n",
    "    :return: Reconstructed image as a NumPy array.\n",
    "    \"\"\"\n",
    "    reconstructed = np.zeros(image_shape, dtype=np.float64)\n",
    "\n",
    "    # Fill known values (edges) into the reconstructed image\n",
    "    reconstructed[edge_image > 0] = quantized_values[:np.sum(edge_image > 0)]\n",
    "\n",
    "    # Solve Laplace's equation for missing values\n",
    "    mask = reconstructed == 0\n",
    "    while np.any(mask):\n",
    "        laplace_values = laplace(reconstructed)\n",
    "        reconstructed[mask] += laplace_values[mask]\n",
    "\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def process_images(image_folder, output_folder, q=4, d=5):\n",
    "    \"\"\"\n",
    "    Main function to process images for edge-based compression.\n",
    "    :param image_folder: Folder containing input images.\n",
    "    :param output_folder: Folder to save outputs.\n",
    "    :param q: Quantization level.\n",
    "    :param d: Subsampling step.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.endswith(('.jpg')):#(('.png', '.bmp')):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            image = np.array(Image.open(image_path).convert('L'))\n",
    "\n",
    "            # Step 1: Detect edges\n",
    "            edge_image = detect_edges(image)\n",
    "            print(edge_image)\n",
    "            # Step 2: Encode edges\n",
    "            encoded_edges = encode_edges(edge_image)\n",
    "            print('hello')\n",
    "\n",
    "            # Step 3: Quantize and subsample\n",
    "            quantized_values = quantize_and_subsample(image, edge_image, q, d)\n",
    "            print('hi')\n",
    "            # Step 4: Compress quantized data\n",
    "            huffman_dict, compressed_data = huffman_encode(quantized_values)\n",
    "            print('hey')\n",
    "            # Step 5: Reconstruct the image\n",
    "            reconstructed_image = reconstruct_image(edge_image, quantized_values, image.shape)\n",
    "            print('hola')\n",
    "            # Save results\n",
    "            Image.fromarray(edge_image).save(os.path.join(output_folder, f\"edges_{image_name}\"))\n",
    "            Image.fromarray(reconstructed_image.astype(np.uint8)).save(os.path.join(output_folder, f\"reconstructed_{image_name}\"))\n",
    "\n",
    "            print(f\"Processed {image_name}: Compression achieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "hello\n",
      "hi\n",
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:555: RuntimeWarning: overflow encountered in add\n",
      "  output += tmp\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_50760\\2995669374.py:20: RuntimeWarning: invalid value encountered in add\n",
      "  reconstructed[mask] += laplace_values[mask]\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:555: RuntimeWarning: invalid value encountered in add\n",
      "  output += tmp\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    input_folder = \"input_images\"  # Folder containing input images (e.g., BMP/PNG)\n",
    "    output_folder = \"output_images\"  # Folder to save output (edges and reconstructed images)\n",
    "    quantization_level = 4  # Number of bits for quantization (e.g., 4 bits)\n",
    "    subsampling_step = 5  # Subsampling step for adjacent pixel values\n",
    "\n",
    "    # Ensure folders exist\n",
    "    if not os.path.exists(input_folder):\n",
    "        raise ValueError(f\"Input folder '{input_folder}' does not exist. Add images to this folder.\")\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Call the main processing function\n",
    "    process_images(input_folder, output_folder, quantization_level, subsampling_step)\n",
    "    \n",
    "    print(\"Image compression and reconstruction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
